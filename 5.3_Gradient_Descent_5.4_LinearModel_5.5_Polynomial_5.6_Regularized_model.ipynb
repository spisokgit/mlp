{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "# y = 4X + 6 식을 근사(w1=4, w0=6). random 값은 Noise를 위해 만듬\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 6 +4 * X+np.random.randn(100,1)\n",
    "\n",
    "# X, y 데이터 셋 scatter plot으로 시각화\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1 과 w0 를 업데이트 할 w1_update, w0_update를 반환. \n",
    "def get_weight_updates(w1, w0, X, y, learning_rate=0.01):\n",
    "    N = len(y)\n",
    "    # 먼저 w1_update, w0_update를 각각 w1, w0의 shape와 동일한 크기를 가진 0 값으로 초기화\n",
    "    w1_update = np.zeros_like(w1)\n",
    "    w0_update = np.zeros_like(w0)\n",
    "    # 예측 배열 계산하고 예측과 실제 값의 차이 계산\n",
    "    y_pred = np.dot(X, w1.T) + w0\n",
    "    diff = y-y_pred\n",
    "         \n",
    "    # w0_update를 dot 행렬 연산으로 구하기 위해 모두 1값을 가진 행렬 생성 \n",
    "    w0_factors = np.ones((N,1))\n",
    "\n",
    "    # w1과 w0을 업데이트할 w1_update와 w0_update 계산\n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(X.T, diff))\n",
    "    w0_update = -(2/N)*learning_rate*(np.dot(w0_factors.T, diff))    \n",
    "    \n",
    "    return w1_update, w0_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 인자 iters로 주어진 횟수만큼 반복적으로 w1과 w0를 업데이트 적용함. \n",
    "def gradient_descent_steps(X, y, iters=10000):\n",
    "    # w0와 w1을 모두 0으로 초기화. \n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    \n",
    "    # 인자로 주어진 iters 만큼 반복적으로 get_weight_updates() 호출하여 w1, w0 업데이트 수행. \n",
    "    for ind in range(iters):\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, X, y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "              \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(y, y_pred):\n",
    "    N = len(y) \n",
    "    cost = np.sum(np.square(y - y_pred))/N\n",
    "    return cost\n",
    "\n",
    "w1, w0 = gradient_descent_steps(X, y, iters=1000)\n",
    "print(\"w1:{0:.3f} w0:{1:.3f}\".format(w1[0,0], w0[0,0]))\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_steps(X, y, batch_size=10, iters=1000):\n",
    "    w0 = np.zeros((1,1))\n",
    "    w1 = np.zeros((1,1))\n",
    "    prev_cost = 100000\n",
    "    iter_index =0\n",
    "    \n",
    "    for ind in range(iters):\n",
    "        np.random.seed(ind)\n",
    "        # 전체 X, y 데이터에서 랜덤하게 batch_size만큼 데이터 추출하여 sample_X, sample_y로 저장\n",
    "        stochastic_random_index = np.random.permutation(X.shape[0])\n",
    "        sample_X = X[stochastic_random_index[0:batch_size]]\n",
    "        sample_y = y[stochastic_random_index[0:batch_size]]\n",
    "        # 랜덤하게 batch_size만큼 추출된 데이터 기반으로 w1_update, w0_update 계산 후 업데이트\n",
    "        w1_update, w0_update = get_weight_updates(w1, w0, sample_X, sample_y, learning_rate=0.01)\n",
    "        w1 = w1 - w1_update\n",
    "        w0 = w0 - w0_update\n",
    "    \n",
    "    return w1, w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w0 = stochastic_gradient_descent_steps(X, y, iters=1000)\n",
    "print(\"w1:\",round(w1[0,0],3),\"w0:\",round(w0[0,0],3))\n",
    "y_pred = w1[0,0] * X + w0\n",
    "print('Stochastic Gradient Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston 데이타셋 크기 : (506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "%matplotlib inline\n",
    "\n",
    "# boston 데이타셋 로드\n",
    "boston = load_boston()\n",
    "\n",
    "# boston 데이타셋 DataFrame 변환 \n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "\n",
    "# boston dataset의 target array는 주택 가격임. 이를 PRICE 컬럼으로 DataFrame에 추가함. \n",
    "bostonDF['PRICE'] = boston.target\n",
    "print('Boston 데이타셋 크기 :',bostonDF.shape)\n",
    "bostonDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개의 행과 4개의 열을 가진 subplots를 이용. axs는 4x2개의 ax를 가짐.\n",
    "fig, axs = plt.subplots(figsize=(16,8) , ncols=4 , nrows=2)\n",
    "lm_features = ['RM','ZN','INDUS','NOX','AGE','PTRATIO','LSTAT','RAD']\n",
    "for i , feature in enumerate(lm_features):\n",
    "    row = int(i/4)\n",
    "    col = i%4\n",
    "    # 시본의 regplot을 이용해 산점도와 선형 회귀 직선을 함께 표현\n",
    "    sns.regplot(x=feature , y='PRICE',data=bostonDF , ax=axs[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 17.306 , RMSE : 4.160\n",
      "Variance score : 0.757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error , r2_score\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_target ,test_size=0.3, random_state=156)\n",
    "\n",
    "# Linear Regression OLS로 학습/예측/평가 수행. \n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train ,y_train )\n",
    "y_preds = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('MSE : {0:.3f} , RMSE : {1:.3F}'.format(mse , rmse))\n",
    "print('Variance score : {0:.3f}'.format(r2_score(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('절편 값:',lr.intercept_)\n",
    "print('회귀 계수값:', np.round(lr.coef_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수를 큰 값 순으로 정렬하기 위해 Series로 생성. index가 컬럼명에 유의\n",
    "coeff = pd.Series(data=np.round(lr.coef_, 1), index=X_data.columns )\n",
    "coeff.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "lr = LinearRegression()\n",
    "\n",
    "# cross_val_score( )로 5 Fold 셋으로 MSE 를 구한 뒤 이를 기반으로 다시  RMSE 구함. \n",
    "neg_mse_scores = cross_val_score(lr, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "# cross_val_score(scoring=\"neg_mean_squared_error\")로 반환된 값은 모두 음수 \n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. Polynomial Regression과 오버피팅/언더피팅 이해\n",
    "### Polynomial Regression 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "# 다항식으로 변환한 단항식 생성, [[0,1],[2,3]]의 2X2 행렬 생성\n",
    "X = np.arange(4).reshape(2,2)\n",
    "print('일차 단항식 계수 feature:\\n',X )\n",
    "\n",
    "# degree = 2 인 2차 다항식으로 변환하기 위해 PolynomialFeatures를 이용하여 변환\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X)\n",
    "poly_ftr = poly.transform(X)\n",
    "print('변환된 2차 다항식 계수 feature:\\n', poly_ftr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_func(X):\n",
    "    y = 1 + 2 * X + X ** 2 + X ** 3\n",
    "    return y\n",
    "\n",
    "X = np.arange(4).reshape(2,2)\n",
    "print('일차 단항식 계수 feature: \\n' ,X)\n",
    "y = polynomial_func(X)\n",
    "print('삼차 다항식 결정값: \\n', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 차 다항식 변환 \n",
    "poly_ftr = PolynomialFeatures(degree=3).fit_transform(X)\n",
    "print('3차 다항식 계수 feature: \\n',poly_ftr)\n",
    "\n",
    "# Linear Regression에 3차 다항식 계수 feature와 3차 다항식 결정값으로 학습 후 회귀 계수 확인\n",
    "model = LinearRegression()\n",
    "model.fit(poly_ftr,y)\n",
    "print('Polynomial 회귀 계수\\n' , np.round(model.coef_, 2))\n",
    "print('Polynomial 회귀 Shape :', model.coef_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def polynomial_func(X):\n",
    "    y = 1 + 2 * X + X ** 2 + X ** 3\n",
    "    return y\n",
    "\n",
    "# Pipeline 객체로 Streamline 하게 Polynomial Feature변환과 Linear Regression을 연결\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
    "                  ('linear', LinearRegression())])\n",
    "X = np.arange(4).reshape(2,2)\n",
    "y = polynomial_func(X)\n",
    "\n",
    "model = model.fit(X, y)\n",
    "print('Polynomial 회귀 계수\\n', np.round(model.named_steps['linear'].coef_, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression 을 이용한 Underfitting, Overfitting 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "# random 값으로 구성된 X값에 대해 Cosine 변환값을 반환. \n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "# X는 0 부터 1까지 30개의 random 값을 순서대로 sampling 한 데이타 입니다.  \n",
    "np.random.seed(0)\n",
    "n_samples = 30\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "\n",
    "# y 값은 cosine 기반의 true_fun() 에서 약간의 Noise 변동값을 더한 값입니다. \n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "# 다항 회귀의 차수(degree)를 1, 4, 15로 각각 변화시키면서 비교합니다. \n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "    \n",
    "    # 개별 degree별로 Polynomial 변환합니다. \n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X.reshape(-1, 1), y)\n",
    "    \n",
    "    # 교차 검증으로 다항 회귀를 평가합니다. \n",
    "    scores = cross_val_score(pipeline, X.reshape(-1,1), y,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    coefficients = pipeline.named_steps['linear_regression'].coef_\n",
    "    print('\\nDegree {0} 회귀 계수는 {1} 입니다.'.format(degrees[i], np.round(coefficients),2))\n",
    "    print('Degree {0} MSE 는 {1:.2f} 입니다.'.format(degrees[i] , -1*np.mean(scores)))\n",
    "    \n",
    "    # 0 부터 1까지 테스트 데이터 세트를 100개로 나눠 예측을 수행합니다. \n",
    "    # 테스트 데이터 세트에 회귀 예측을 수행하고 예측 곡선과 실제 곡선을 그려서 비교합니다.  \n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    # 예측값 곡선\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\") \n",
    "    # 실제 값 곡선\n",
    "    plt.plot(X_test, true_fun(X_test), '--', label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    \n",
    "    plt.xlabel(\"x\"); plt.ylabel(\"y\"); plt.xlim((0, 1)); plt.ylim((-2, 2)); plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. Regularized Linear Models – Ridge, Lasso\n",
    "### Regularized Linear Model - Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 folds 의 개별 Negative MSE scores:  [-11.437 -24.291 -28.17  -74.673 -28.719]\n",
      " 5 folds 의 개별 RMSE scores :  [3.382 4.929 5.308 8.641 5.359]\n",
      " 5 folds 의 평균 RMSE : 5.524 \n"
     ]
    }
   ],
   "source": [
    "# 앞의 LinearRegression예제에서 분할한 feature 데이터 셋인 X_data과 Target 데이터 셋인 Y_target 데이터셋을 그대로 이용 \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0 일 때 5 folds 의 평균 RMSE : 5.836 \n",
      "alpha 0.1 일 때 5 folds 의 평균 RMSE : 5.796 \n",
      "alpha 1 일 때 5 folds 의 평균 RMSE : 5.659 \n",
      "alpha 10 일 때 5 folds 의 평균 RMSE : 5.524 \n",
      "alpha 100 일 때 5 folds 의 평균 RMSE : 5.332 \n"
     ]
    }
   ],
   "source": [
    "# Ridge에 사용될 alpha 파라미터의 값들을 정의\n",
    "alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 alpha에 따른 회귀 계수 값을 시각화하기 위해 5개의 열로 된 맷플롯립 축 생성  \n",
    "fig , axs = plt.subplots(figsize=(18,6) , nrows=1 , ncols=5)\n",
    "# 각 alpha에 따른 회귀 계수 값을 데이터로 저장하기 위한 DataFrame 생성  \n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
    "for pos , alpha in enumerate(alphas) :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_data , y_target)\n",
    "    # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.  \n",
    "    coeff = pd.Series(data=ridge.coef_ , index=X_data.columns )\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3,6)\n",
    "    sns.barplot(x=coeff.values , y=coeff.index, ax=axs[pos])\n",
    "\n",
    "# for 문 바깥에서 맷플롯립의 show 호출 및 alpha에 따른 피처별 회귀 계수를 DataFrame으로 표시\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:10</th>\n",
       "      <th>alpha:100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.804752</td>\n",
       "      <td>3.813177</td>\n",
       "      <td>3.849256</td>\n",
       "      <td>3.698132</td>\n",
       "      <td>2.331966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.688561</td>\n",
       "      <td>2.671849</td>\n",
       "      <td>2.554221</td>\n",
       "      <td>1.953452</td>\n",
       "      <td>0.638647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.305655</td>\n",
       "      <td>0.303105</td>\n",
       "      <td>0.289650</td>\n",
       "      <td>0.279016</td>\n",
       "      <td>0.314915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.046395</td>\n",
       "      <td>0.046546</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.049547</td>\n",
       "      <td>0.054470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>-0.008547</td>\n",
       "      <td>-0.042745</td>\n",
       "      <td>-0.052626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.009471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.010674</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.012329</td>\n",
       "      <td>-0.012415</td>\n",
       "      <td>-0.012907</td>\n",
       "      <td>-0.013989</td>\n",
       "      <td>-0.015852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.107171</td>\n",
       "      <td>-0.106612</td>\n",
       "      <td>-0.103622</td>\n",
       "      <td>-0.100352</td>\n",
       "      <td>-0.101451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.525467</td>\n",
       "      <td>-0.526678</td>\n",
       "      <td>-0.534072</td>\n",
       "      <td>-0.560097</td>\n",
       "      <td>-0.661312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.953464</td>\n",
       "      <td>-0.941449</td>\n",
       "      <td>-0.876633</td>\n",
       "      <td>-0.798335</td>\n",
       "      <td>-0.829503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.475759</td>\n",
       "      <td>-1.459773</td>\n",
       "      <td>-1.372570</td>\n",
       "      <td>-1.248455</td>\n",
       "      <td>-1.153157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-17.795759</td>\n",
       "      <td>-16.711712</td>\n",
       "      <td>-10.793436</td>\n",
       "      <td>-2.374959</td>\n",
       "      <td>-0.263245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alpha:0  alpha:0.1    alpha:1  alpha:10  alpha:100\n",
       "RM        3.804752   3.813177   3.849256  3.698132   2.331966\n",
       "CHAS      2.688561   2.671849   2.554221  1.953452   0.638647\n",
       "RAD       0.305655   0.303105   0.289650  0.279016   0.314915\n",
       "ZN        0.046395   0.046546   0.047414  0.049547   0.054470\n",
       "INDUS     0.020860   0.016293  -0.008547 -0.042745  -0.052626\n",
       "B         0.009393   0.009449   0.009754  0.010117   0.009471\n",
       "AGE       0.000751  -0.000212  -0.005368 -0.010674   0.001230\n",
       "TAX      -0.012329  -0.012415  -0.012907 -0.013989  -0.015852\n",
       "CRIM     -0.107171  -0.106612  -0.103622 -0.100352  -0.101451\n",
       "LSTAT    -0.525467  -0.526678  -0.534072 -0.560097  -0.661312\n",
       "PTRATIO  -0.953464  -0.941449  -0.876633 -0.798335  -0.829503\n",
       "DIS      -1.475759  -1.459773  -1.372570 -1.248455  -1.153157\n",
       "NOX     -17.795759 -16.711712 -10.793436 -2.374959  -0.263245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "sort_column = 'alpha:'+str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "# alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환 \n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    if verbose : print('####### ', model_name , '#######')\n",
    "    for param in params:\n",
    "        if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores = cross_val_score(model, X_data_n, \n",
    "                                             y_target_n, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f} '.format(param, avg_rmse))\n",
    "        # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
    "        model.fit(X_data , y_target)\n",
    "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가. \n",
    "        coeff = pd.Series(data=model.coef_ , index=X_data.columns )\n",
    "        colname='alpha:'+str(param)\n",
    "        coeff_df[colname] = coeff\n",
    "    return coeff_df\n",
    "# end of get_linear_regre_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  Lasso #######\n",
      "alpha 0.07일 때 5 폴드 세트의 평균 RMSE: 5.618 \n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.621 \n",
      "alpha 0.5일 때 5 폴드 세트의 평균 RMSE: 5.672 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.776 \n",
      "alpha 3일 때 5 폴드 세트의 평균 RMSE: 6.189 \n"
     ]
    }
   ],
   "source": [
    "# 라쏘에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "lasso_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_lasso_df =get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.785460</td>\n",
       "      <td>3.698943</td>\n",
       "      <td>2.494509</td>\n",
       "      <td>0.946786</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.436287</td>\n",
       "      <td>0.957097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.270327</td>\n",
       "      <td>0.274112</td>\n",
       "      <td>0.277118</td>\n",
       "      <td>0.264175</td>\n",
       "      <td>0.061867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.049026</td>\n",
       "      <td>0.049179</td>\n",
       "      <td>0.049528</td>\n",
       "      <td>0.049169</td>\n",
       "      <td>0.037231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.011675</td>\n",
       "      <td>-0.010006</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.042495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014287</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>-0.015440</td>\n",
       "      <td>-0.015209</td>\n",
       "      <td>-0.008602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.041924</td>\n",
       "      <td>-0.036425</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.097061</td>\n",
       "      <td>-0.096788</td>\n",
       "      <td>-0.082662</td>\n",
       "      <td>-0.063423</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.561179</td>\n",
       "      <td>-0.569509</td>\n",
       "      <td>-0.656853</td>\n",
       "      <td>-0.761433</td>\n",
       "      <td>-0.807679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.765456</td>\n",
       "      <td>-0.771003</td>\n",
       "      <td>-0.759070</td>\n",
       "      <td>-0.723199</td>\n",
       "      <td>-0.265072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.176150</td>\n",
       "      <td>-1.160121</td>\n",
       "      <td>-0.936447</td>\n",
       "      <td>-0.669009</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.785460   3.698943   2.494509  0.946786  0.000000\n",
       "CHAS       1.436287   0.957097   0.000000  0.000000  0.000000\n",
       "RAD        0.270327   0.274112   0.277118  0.264175  0.061867\n",
       "ZN         0.049026   0.049179   0.049528  0.049169  0.037231\n",
       "B          0.010326   0.010327   0.009532  0.008291  0.006510\n",
       "NOX       -0.000000  -0.000000  -0.000000 -0.000000  0.000000\n",
       "AGE       -0.011675  -0.010006   0.003630  0.020927  0.042495\n",
       "TAX       -0.014287  -0.014567  -0.015440 -0.015209 -0.008602\n",
       "INDUS     -0.041924  -0.036425  -0.005109 -0.000000 -0.000000\n",
       "CRIM      -0.097061  -0.096788  -0.082662 -0.063423 -0.000000\n",
       "LSTAT     -0.561179  -0.569509  -0.656853 -0.761433 -0.807679\n",
       "PTRATIO   -0.765456  -0.771003  -0.759070 -0.723199 -0.265072\n",
       "DIS       -1.176150  -1.160121  -0.936447 -0.669009 -0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반환된 coeff_lasso_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엘라스틱넷 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######  ElasticNet #######\n",
      "alpha 0.07일 때 5 폴드 세트의 평균 RMSE: 5.546 \n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.530 \n",
      "alpha 0.5일 때 5 폴드 세트의 평균 RMSE: 5.468 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.596 \n",
      "alpha 3일 때 5 폴드 세트의 평균 RMSE: 6.068 \n"
     ]
    }
   ],
   "source": [
    "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "# l1_ratio는 0.7로 고정\n",
    "elastic_alphas = [ 0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df =get_linear_reg_eval('ElasticNet', params=elastic_alphas,\n",
    "                                      X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.570126</td>\n",
       "      <td>3.410274</td>\n",
       "      <td>1.915894</td>\n",
       "      <td>0.937179</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.332117</td>\n",
       "      <td>0.980900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.278304</td>\n",
       "      <td>0.282881</td>\n",
       "      <td>0.300449</td>\n",
       "      <td>0.289167</td>\n",
       "      <td>0.147089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.050074</td>\n",
       "      <td>0.050586</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0.052126</td>\n",
       "      <td>0.038281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.007029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.010084</td>\n",
       "      <td>-0.008248</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.020360</td>\n",
       "      <td>0.043445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014519</td>\n",
       "      <td>-0.014810</td>\n",
       "      <td>-0.016044</td>\n",
       "      <td>-0.016213</td>\n",
       "      <td>-0.011417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.044641</td>\n",
       "      <td>-0.042520</td>\n",
       "      <td>-0.023093</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.098392</td>\n",
       "      <td>-0.098179</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.073471</td>\n",
       "      <td>-0.019596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.178164</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.575540</td>\n",
       "      <td>-0.588404</td>\n",
       "      <td>-0.694327</td>\n",
       "      <td>-0.760714</td>\n",
       "      <td>-0.800276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.779878</td>\n",
       "      <td>-0.785066</td>\n",
       "      <td>-0.791232</td>\n",
       "      <td>-0.738850</td>\n",
       "      <td>-0.423093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.189080</td>\n",
       "      <td>-1.173268</td>\n",
       "      <td>-0.975771</td>\n",
       "      <td>-0.725297</td>\n",
       "      <td>-0.031389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.570126   3.410274   1.915894  0.937179  0.000000\n",
       "CHAS       1.332117   0.980900   0.000000  0.000000  0.000000\n",
       "RAD        0.278304   0.282881   0.300449  0.289167  0.147089\n",
       "ZN         0.050074   0.050586   0.052860  0.052126  0.038281\n",
       "B          0.010200   0.010145   0.009182  0.008373  0.007029\n",
       "AGE       -0.010084  -0.008248   0.007777  0.020360  0.043445\n",
       "TAX       -0.014519  -0.014810  -0.016044 -0.016213 -0.011417\n",
       "INDUS     -0.044641  -0.042520  -0.023093 -0.000000 -0.000000\n",
       "CRIM      -0.098392  -0.098179  -0.088550 -0.073471 -0.019596\n",
       "NOX       -0.178164  -0.000000  -0.000000 -0.000000 -0.000000\n",
       "LSTAT     -0.575540  -0.588404  -0.694327 -0.760714 -0.800276\n",
       "PTRATIO   -0.779878  -0.785066  -0.791232 -0.738850 -0.423093\n",
       "DIS       -1.189080  -1.173268  -0.975771 -0.725297 -0.031389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반환된 coeff_elastic_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델을 위한 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\n",
    "# p_degree는 다향식 특성을 추가할 때 적용. p_degree는 2이상 부여하지 않음. \n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "\n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, \n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 변환 유형:None, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.796 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.659 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.524 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 5.332 \n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.834 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.810 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.643 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 5.424 \n",
      "\n",
      "## 변환 유형:Standard, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 8.776 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 6.849 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.487 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 4.631 \n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.770 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 5.468 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.755 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 7.635 \n",
      "\n",
      "## 변환 유형:MinMax, Polynomial Degree:2\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 5.294 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 4.320 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 5.186 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 6.538 \n",
      "\n",
      "## 변환 유형:Log, Polynomial Degree:None\n",
      "alpha 0.1일 때 5 폴드 세트의 평균 RMSE: 4.772 \n",
      "alpha 1일 때 5 폴드 세트의 평균 RMSE: 4.676 \n",
      "alpha 10일 때 5 폴드 세트의 평균 RMSE: 4.835 \n",
      "alpha 100일 때 5 폴드 세트의 평균 RMSE: 6.244 \n"
     ]
    }
   ],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출. \n",
    "alphas = [0.1, 1, 10, 100]\n",
    "#변환 방법은 모두 6개, 원본 그대로, 표준정규분포, 표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환 \n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
    "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], \n",
    "                                    input_data=X_data)\n",
    "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
    "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, \n",
    "                        y_target_n=y_target, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
