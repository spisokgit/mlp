{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KoNLPy\n",
    "* https://konlpy-ko.readthedocs.io/ko/v0.4.3/api/konlpy.tag/\n",
    "* 꼬꼬마(Kkma), 한나눔(Hannanum), Komoran, 은전한닢프로젝트(Mecab), Twitter(OKt)모두 사용가능\n",
    "* Mecab 윈도우환경 구동되지 않음, \n",
    "* 윈도우 설치시 자바클래스 호출을 위한 JPype1 모듈설치 (JAVA_HOME, PATH)\n",
    "    - 맞는 .whl 설치 (pip)\n",
    "    - pip install --upgrade pip\n",
    "    - pip install JPype1-0.6.3-cp36-cp36m-win_amd64.whl (conda install -c conda-forge jpype1)\n",
    "    - JAVA_HOME 일반적으로 bin앞 폴더까지이지만 jpype1에서는 \\bin\\server (jvm.dll)이 있는 폴더까지 지정\n",
    "    (- PATH)\n",
    "    - pip install konlpy (conda install -c conda-forge konlpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"axes_unicode_minus\" on line 3 in\n",
      "/home/jovyan/.config/matplotlib/matplotlibrc.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15745720</td>\n",
       "      <td>재미있고 또 보고 싶네요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15862701</td>\n",
       "      <td>여러분 인생에 한시간을 버리고 싶다면 이 영화를 꼭 보시기 바랍니다. 내용도 전개도...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15122150</td>\n",
       "      <td>무조건 강추. 실화가 아닌 영화라 해도 강추인데. 실화라는게 믿겨지지 않을 정도. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0  15745720                                     재미있고 또 보고 싶네요.      1\n",
       "1  15862701  여러분 인생에 한시간을 버리고 싶다면 이 영화를 꼭 보시기 바랍니다. 내용도 전개도...      0\n",
       "2  15122150  무조건 강추. 실화가 아닌 영화라 해도 강추인데. 실화라는게 믿겨지지 않을 정도. ...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('./data/ratings_train.txt', sep='\\t')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    75090\n",
       "0    74910\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                           document  label\n",
      "0  15745720                                     재미있고 또 보고 싶네요.      1\n",
      "1  15862701  여러분 인생에 한시간을 버리고 싶다면 이 영화를 꼭 보시기 바랍니다. 내용도 전개도...      0\n",
      "2  15122150  무조건 강추. 실화가 아닌 영화라 해도 강추인데. 실화라는게 믿겨지지 않을 정도. ...      1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      "id          150000 non-null int64\n",
      "document    150000 non-null object\n",
      "label       150000 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "# null -> 공백\n",
    "train_df = train_df.fillna('')\n",
    "# 숫자 -> 공백\n",
    "train_df['document'] = train_df['document'].apply(lambda x: re.sub(r\"\\d+\", \" \", x))\n",
    "print(train_df.head(3))\n",
    "print(train_df.info())\n",
    "\n",
    "test_df = pd.read_csv('ratings_test.txt', sep='\\t')\n",
    "test_df = test_df.fillna(' ')\n",
    "test_df['document'] = test_df['document'].apply(lambda x: re.sub(r\"\\d+\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 단어 벡터화 (문장 -> 형태소단어로 토큰화)\n",
    "from konlpy.tag import Twitter\n",
    "# Mecab japan -> korean 응용 not dependency java\n",
    "# Twitter korean Text\n",
    "# nouns : 명사 추출\n",
    "# morphs : 형태소 추출\n",
    "# pos : 품사 부착\n",
    "tw = Twitter()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = tw.morphs(text) # 문장(text) -> 형태소단어로 토큰화 list 반환\n",
    "    #print(tokens_ko)\n",
    "    return tokens_ko\n",
    "#tw_tokenizer(u'아버지가 방에 들어 가신다')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Twitter 객체의 morphs( ) 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2) \n",
    "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train_df['document'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   41.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4.5} 0.8799\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 을 이용하여 감성 분석 Classification 수행. \n",
    "lg_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# Parameter C 최적화를 위해 GridSearchCV 를 이용. \n",
    "params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\n",
    "grid_cv = GridSearchCV(lg_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train , train_df['label'] )\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도:  0.84206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 학습 데이터를 적용한 TfidfVectorizer를 이용하여 테스트 데이터를 TF-IDF 값으로 Feature 변환함. \n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
    "\n",
    "# classifier 는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "preds = best_estimator.predict(tfidf_matrix_test)\n",
    "\n",
    "print('Logistic Regression 정확도: ',accuracy_score(test_df['label'],preds))\n",
    "# 4분정도 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
